{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGofTRfzdJVjbM/2ofDLdu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sara-kaczmarek/LLMB4ABSC/blob/main/TRY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeEOt0eCCIEf"
      },
      "outputs": [],
      "source": [
        "# ========== MAKE CHOICES ==========\n",
        "\n",
        "# Choose dataset from options: \"Lapt14\", Rest14\", \"Rest15\" or \"Rest16\"\n",
        "dataset_choice = \"Rest16\"\n",
        "\n",
        "domain = \"laptop\" if dataset_choice == \"Lapt14\" else \"restaurant\"\n",
        "\n",
        "# Choose LLM's from options: \"mistral\", \"llama\", \"gemma\"\n",
        "model_choice = \"gemma\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only run first time\n",
        "#!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "#!pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "#!pip install transformers==4.51.3\n",
        "#!pip install --no-deps unsloth\n",
        "#!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "M_o95VYUCK09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "code_path = \"/content/drive/My Drive/Master Thesis/Code\"\n",
        "if code_path not in sys.path:\n",
        "    sys.path.append(code_path)\n",
        "\n",
        "from data_prep import *\n",
        "from evaluation_measures import *\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import re"
      ],
      "metadata": {
        "id": "QgJkL0UkCMRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LLM\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model_mapping = {\n",
        "    \"mistral\": \"unsloth/mistral-7b-v0.3-bnb-4bit\",\n",
        "    \"llama\": \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n",
        "    \"gemma\": \"unsloth/gemma-2-9b-bnb-4bit\"\n",
        "}\n",
        "\n",
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_mapping[model_choice],\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    device_map = \"auto\"\n",
        ")\n",
        "\n",
        "# Load SimCSE\n",
        "from sentence_transformers import util, SentenceTransformer\n",
        "model_sbert = SentenceTransformer(\"princeton-nlp/sup-simcse-roberta-base\")"
      ],
      "metadata": {
        "id": "KCmJauJnCNR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####### Preparation for Table 3 #######\n",
        "df_train = load_xml_to_df(f\"/content/drive/My Drive/Master Thesis/Data/Train_Data/{dataset_choice}_Train.xml\")\n",
        "df_test = load_xml_to_df(f\"/content/drive/My Drive/Master Thesis/Data/Test_Data/{dataset_choice}_Test.xml\")\n",
        "\n",
        "df_train = compute_simcse_embeddings(df_train)\n",
        "\n",
        "rename_cols = {\"sentiment\": \"polarity\", \"original_aspect\": \"aspect\", \"generated_sentence\": \"sentence\"}\n",
        "\n",
        "base_path = f\"/content/drive/My Drive/Master Thesis/Data/{model_choice}\"\n",
        "\n",
        "df_synthetic= load_and_sample(f\"{base_path}/Synthetic_{dataset_choice}_{model_choice}.csv\", rename_cols, len(df_train))\n",
        "df_synthetic = df_synthetic.dropna(subset=[\"generated_sentence\"]).reset_index(drop=True)\n",
        "df_synthetic = compute_simcse_embeddings(df_synthetic)\n",
        "\n",
        "df_filtered = load_and_sample(f\"{base_path}/Filtered_{dataset_choice}_{model_choice}.csv\", rename_cols, len(df_train))\n",
        "df_filtered = compute_simcse_embeddings(df_filtered)"
      ],
      "metadata": {
        "id": "agtTRivECNWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####### Get Results for Table 3 #######\n",
        "\n",
        "results_dict = {\n",
        "    \"Metric\": []\n",
        "}\n",
        "\n",
        "shots = [3, 6]\n",
        "strategies = [\"random_equal\", \"simcse_equal\"]  # Rb and SSb\n",
        "few_shot_runs = {}\n",
        "\n",
        "for k in shots:\n",
        "    for scenario in strategies:\n",
        "        print(f\"\\n\\n========== Running {k}-Shot Scenario: {scenario} ==========\\n\")\n",
        "\n",
        "        start = time.time()\n",
        "        df_results_few = run_inference(\n",
        "            df_test,\n",
        "            sc_fewshot_prompt,\n",
        "            df=df_train, # Choose df here\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            k=k,\n",
        "            scenario=scenario\n",
        "        )\n",
        "        end = time.time()\n",
        "\n",
        "        metrics_few = evaluate_predictions(df_results_few)\n",
        "        metrics_few[\"Time (seconds)\"] = round(end - start, 4)\n",
        "\n",
        "        if not results_dict[\"Metric\"]:\n",
        "            results_dict[\"Metric\"] = list(metrics_few.keys())\n",
        "\n",
        "        label = f\"{k}-Shot ({scenario})\"\n",
        "        results_dict[label] = [metrics_few.get(metric, None) for metric in results_dict[\"Metric\"]]\n",
        "\n",
        "        print_confusion_matrix(df_results_few)\n",
        "        few_shot_runs[f\"{k}_{scenario}\"] = df_results_few\n",
        "\n",
        "df_combined = pd.DataFrame(results_dict)\n",
        "display(df_combined)\n",
        "\n",
        "output_path = f\"/content/drive/My Drive/Master Thesis/Data/Results/FewShotAnnotatedResults_{dataset_choice}_{model_choice}.csv\"\n",
        "df_combined.to_csv(output_path, index=False)\n",
        "print(f\"File saved to {output_path}\")"
      ],
      "metadata": {
        "id": "XkzWQZqXCNY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsB-kzSeCNa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OBz8R-V0CNc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "agd1fr77CNfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6F1RbhdCNg5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}