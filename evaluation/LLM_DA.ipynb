{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhTaq8Nk0XJD"
      },
      "outputs": [],
      "source": [
        "# ========== MAKE CHOICES ==========\n",
        "\n",
        "# Choose dataset from options: \"Lapt14\", Rest14\", \"Rest15\" or \"Rest16\"\n",
        "dataset_choice = \"Rest14\"\n",
        "\n",
        "domain = \"laptop\" if dataset_choice == \"Lapt14\" else \"restaurant\"\n",
        "\n",
        "# Choose LLM's from options: \"mistral\", \"llama\", \"gemma\"\n",
        "model_choice = \"gemma\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oTTXa5HAwosi"
      },
      "outputs": [],
      "source": [
        "# Only run first time\n",
        "#pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "#!pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "#!pip install transformers==4.51.3\n",
        "#!pip install --no-deps unsloth\n",
        "#!pip install sentence-transformers\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model_mapping = {\n",
        "    \"mistral\": \"unsloth/mistral-7b-v0.3-bnb-4bit\",\n",
        "    \"llama\": \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n",
        "    \"gemma\": \"unsloth/gemma-2-9b-bnb-4bit\"\n",
        "}\n",
        "\n",
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_mapping[model_choice],\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    device_map = \"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CEznfx89a8l",
        "outputId": "7440292c-d0e1-49f3-f6e5-f12ea0fa122c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "code_path = \"/content/drive/My Drive/Master Thesis/Code\"\n",
        "if code_path not in sys.path:\n",
        "    sys.path.append(code_path)\n",
        "\n",
        "from data_prep import load_xml_to_df\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVfat38G336a"
      },
      "outputs": [],
      "source": [
        "def rewrite_prompt(sentence, aspect, sentiment, model, tokenizer, max_tokens=60, device=\"cuda\"):\n",
        "    prompt = (\n",
        "        \"You are an expert at rewriting sentences while keeping the same meaning, aspect, and sentiment.\\n\"\n",
        "        \"Given a sentence, aspect, and sentiment label, rewrite it in a natural and fluent way.\\n\"\n",
        "        \"Do not change the sentiment or aspect.\\n\\n\"\n",
        "        f\"Sentence: {sentence}\\n\"\n",
        "        f\"Aspect: {aspect}\\n\"\n",
        "        f\"Sentiment: {sentiment}\\n\"\n",
        "        \"Rewritten sentence:\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_tokens,\n",
        "        temperature=0.9,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        repetition_penalty=1.2,\n",
        "        no_repeat_ngram_size=3\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    rewritten = decoded.replace(prompt, \"\").strip()\n",
        "    rewritten = rewritten.split(\".\")[0].strip() + \".\"\n",
        "    return rewritten\n",
        "\n",
        "df_train = load_xml_to_df(f\"/content/drive/My Drive/Master Thesis/Data/Train_Data/{dataset_choice}_Train.xml\")\n",
        "\n",
        "rewritten_records = []\n",
        "\n",
        "for _, row in tqdm(df_train.iterrows(), total=len(df_train), desc=\"Rewriting sentences\"):\n",
        "    orig_sentence = row[\"sentence\"]\n",
        "    aspect = row[\"aspect\"]\n",
        "    sentiment = row[\"polarity\"]\n",
        "\n",
        "    try:\n",
        "        rewritten_sentence = rewrite_prompt(orig_sentence, aspect, sentiment, model, tokenizer, device=\"cuda\")\n",
        "\n",
        "        if rewritten_sentence and rewritten_sentence != orig_sentence:\n",
        "            rewritten_records.append({\n",
        "                \"sentence\": rewritten_sentence,\n",
        "                \"aspect\": aspect,\n",
        "                \"polarity\": sentiment\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error rewriting row: {e}\")\n",
        "\n",
        "df_rewritten = pd.DataFrame(rewritten_records)\n",
        "df_augmented = pd.concat([df_train, df_rewritten], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Yp9aDCa3626"
      },
      "outputs": [],
      "source": [
        "output_path = f\"/content/drive/My Drive/Master Thesis/Data/DA/LLM_R_{dataset_choice}_{model_choice}.csv\"\n",
        "df_augmented.to_csv(output_path, index=False)\n",
        "print(f\"File saved to {output_path}\")\n",
        "\n",
        "display(df_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh-z02d64d5n"
      },
      "outputs": [],
      "source": [
        "def annotate_prompt(sentence, aspect, model, tokenizer, max_tokens=20, device=\"cuda\"):\n",
        "    prompt = (\n",
        "        \"You are an expert in aspect-based sentiment analysis.\\n\"\n",
        "        \"Given a sentence and an aspect, determine whether the sentiment expressed towards that aspect is positive, neutral, or negative.\\n\"\n",
        "        f\"Sentence: {sentence}\\n\"\n",
        "        f\"Aspect: {aspect}\\n\"\n",
        "        \"Sentiment:\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_tokens,\n",
        "        temperature=0.0,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    sentiment = decoded.replace(prompt, \"\").strip().split()[0].lower()\n",
        "\n",
        "    return sentiment\n",
        "\n",
        "df_train = load_xml_to_df(f\"/content/drive/My Drive/Master Thesis/Data/Train_Data/{dataset_choice}_Train.xml\")\n",
        "\n",
        "annotated_records = []\n",
        "\n",
        "for _, row in tqdm(df_train.iterrows(), total=len(df_train), desc=\"Annotating sentences\"):\n",
        "    orig_sentence = row[\"sentence\"]\n",
        "    aspect = row[\"aspect\"]\n",
        "\n",
        "    try:\n",
        "        predicted_sentiment = annotate_prompt(orig_sentence, aspect, model, tokenizer, device=\"cuda\")\n",
        "\n",
        "        annotated_records.append({\n",
        "            \"sentence\": orig_sentence,\n",
        "            \"aspect\": aspect,\n",
        "            \"polarity\": predicted_sentiment\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error annotating row: {e}\")\n",
        "\n",
        "df_annotated = pd.DataFrame(annotated_records)\n",
        "df_augmented = pd.concat([df_train, df_annotated], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp7dL29x4gw0"
      },
      "outputs": [],
      "source": [
        "output_path = f\"/content/drive/My Drive/Master Thesis/Data/DA/LLM_A_{dataset_choice}_{model_choice}.csv\"\n",
        "df_augmented.to_csv(output_path, index=False)\n",
        "print(f\"File saved to {output_path}\")\n",
        "\n",
        "display(df_augmented)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
